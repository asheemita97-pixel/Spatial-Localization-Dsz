{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asheemita97-pixel/Spatial-Localization-Dsz/blob/main/co.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OIqrMpFJLag_"
      },
      "outputs": [],
      "source": [
        "# produce (ny, nx) mask matrix and (N_points,2) coordinate list, then visualize.\n",
        "#\n",
        "# Given:\n",
        "#   larger diameter = 1.995 um (major axis length)\n",
        "#   smaller diameter = 0.798 um (minor axis length)\n",
        "#\n",
        "# Outputs:\n",
        "#   X, Y          -> full 2D grid arrays (ny, nx)\n",
        "#   mask          -> boolean array (ny, nx) True = point inside ellipse\n",
        "#   points        -> (N_inside, 2) array of (x,y) coordinates inside ellipse\n",
        "#   dx, dy        -> grid spacing used (equal here)\n",
        "#   phi           -> example variable array (ny, nx) initialized for FTCS\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "major_diam = 1.995    # micrometers (largest diameter)\n",
        "minor_diam = 0.798    # micrometers (smallest diameter)\n",
        "target_N = 1000     # approximate number of points inside the ellipse desired\n",
        "tolerance = 0.05      # +/- tolerance (5%)\n",
        "\n",
        "a = major_diam / 2.0  # semi-major axis (um)\n",
        "b = minor_diam / 2.0  # semi-minor axis (um)\n",
        "\n",
        "area = np.pi * a * b\n",
        "dx = np.sqrt(area / target_N)\n",
        "dy = dx\n",
        "\n",
        "# helper to make grid + mask and return count\n",
        "def build_grid(dx, dy):\n",
        "    # ensure grid includes endpoints by adding a half-step margin\n",
        "    x = np.arange(-a - 1e-12, a + dx/2.0, dx)\n",
        "    y = np.arange(-b - 1e-12, b + dy/2.0, dy)\n",
        "    X, Y = np.meshgrid(x, y)\n",
        "    # ellipse equation (normalized)\n",
        "    mask = (X / a) ** 2 + (Y / b) ** 2 <= 1.0\n",
        "    return X, Y, mask\n",
        "\n",
        "# iteratively adjust dx until N_inside is close to target_N (within tolerance)\n",
        "max_iters = 30\n",
        "for it in range(max_iters):\n",
        "    X, Y, mask = build_grid(dx, dy)\n",
        "    N_inside = np.count_nonzero(mask)\n",
        "    if abs(N_inside - target_N) / target_N <= tolerance:\n",
        "        break\n",
        "    # adjust spacing using proportional scaling\n",
        "    scale = np.sqrt(N_inside / target_N)\n",
        "    dx *= scale\n",
        "    dy *= scale\n",
        "else:\n",
        "    # if loop finishes without break, we still have X,Y,mask from last iteration\n",
        "    N_inside = np.count_nonzero(mask)\n",
        "\n",
        "# prepare outputs\n",
        "points = np.column_stack((X[mask], Y[mask]))   # (N_inside, 2)\n",
        "ny, nx = X.shape\n",
        "mask_int = mask.astype(int)  # 1 inside, 0 outside\n",
        "phi = np.zeros_like(X)       # example variable matrix for FTCS (same shape)\n",
        "\n",
        "# print summary\n",
        "print(f\"Ellipse semi-axes: a = {a:.6f} µm, b = {b:.6f} µm\")\n",
        "print(f\"Grid spacing: dx = {dx:.6e} µm, dy = {dy:.6e} µm\")\n",
        "print(f\"Grid shape: ny = {ny}, nx = {nx}  -> total grid points = {nx*ny}\")\n",
        "print(f\"Points inside ellipse: {N_inside} (target was {target_N})\")\n",
        "print(f\"Points array shape: {points.shape}\")\n",
        "print(\"Mask matrix shape (ny, nx):\", mask.shape)\n",
        "\n",
        "# --- Visualization ---\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12,5))\n",
        "\n",
        "# 1) scatter plot of points (good for checking distribution)\n",
        "ax = axes[0]\n",
        "ax.scatter(points[:,0], points[:,1], s=6, alpha=0.7)\n",
        "# overlay ellipse boundary\n",
        "theta = np.linspace(0, 2*np.pi, 400)\n",
        "xb = a * np.cos(theta)\n",
        "yb = b * np.sin(theta)\n",
        "ax.plot(xb, yb, color='k', linewidth=1)\n",
        "ax.set_aspect('equal', 'box')\n",
        "ax.set_title(f'Point cloud inside ellipse — {N_inside} points')\n",
        "ax.set_xlabel('x (µm)')\n",
        "ax.set_ylabel('y (µm)')\n",
        "ax.grid(alpha=0.25)\n",
        "\n",
        "# 2) mask visualization as pcolormesh (useful to see the matrix layout)\n",
        "ax = axes[1]\n",
        "# pcolormesh requires corner coordinates; construct edges\n",
        "x_edges = np.linspace(-a - dx/2.0, a + dx/2.0, nx+1)\n",
        "y_edges = np.linspace(-b - dy/2.0, b + dy/2.0, ny+1)\n",
        "# show mask as image-like plot\n",
        "pcm = ax.pcolormesh(x_edges, y_edges, mask_int, shading='auto')\n",
        "ax.set_aspect('equal', 'box')\n",
        "ax.set_title('Mask matrix (1 = inside ellipse)')\n",
        "ax.set_xlabel('x (µm)')\n",
        "ax.set_ylabel('y (µm)')\n",
        "fig.colorbar(pcm, ax=ax, label='mask')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# --- Useful helpers for FTCS ---f\n",
        "\n",
        "# To use FTCS on this domain, keep phi (ny,nx) and mask.\n",
        "# Example: iterate only over interior points (exclude outside points)\n",
        "# Note: indexing is phi[row, col] corresponding to Y[row,:], X[:,col]\n",
        "#\n",
        "# Example FTCS update pseudo-code (explicit diffusion, 2D) for interior points:\n",
        "#\n",
        "# alpha = D * dt / dx**2   # diffusion number (choose dt accordingly)\n",
        "# for it in range(num_steps):\n",
        "#     phi_new = phi.copy()\n",
        "#     # update only where mask is True and not on boundary if you want Dirichlet boundary\n",
        "#     interior_idx = np.where(mask)   # returns (rows, cols)\n",
        "#     rows, cols = interior_idx\n",
        "#     # vectorized neighbor access example (careful at domain edges: mask handles outside)\n",
        "#     # here we demonstrate a safe neighbor-sum using shifts:\n",
        "#     # neighbor_sum = (phi[rows+1, cols] + phi[rows-1, cols] + phi[rows, cols+1] + phi[rows, cols-1])\n",
        "#     # phi_new[rows, cols] = phi[rows, cols] + alpha * (neighbor_sum - 4*phi[rows,cols])\n",
        "#     # apply boundary conditions (Dirichlet or Neumann) as needed.\n",
        "#\n",
        "# Save arrays for later:\n",
        "# np.save(\"ellipse_points.npy\", points)\n",
        "# np.save(\"ellipse_mask.npy\", mask_int)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZSHlgTXsLpE7"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "import scipy.ndimage as nd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "# ==============================================================================\n",
        "# 1. HELPER FUNCTIONS\n",
        "# ==============================================================================\n",
        "\n",
        "def get_ellipse_coords(X, Y, a, b):\n",
        "    \"\"\"\n",
        "    Returns normalized radius (rho) and angle (theta) in the transformed\n",
        "    unit-circle space of the ellipse.\n",
        "    rho = 1.0 at the boundary.\n",
        "    theta ranges from -pi to pi.\n",
        "    \"\"\"\n",
        "    # Transform to unit circle space\n",
        "    x_norm = X / a\n",
        "    y_norm = Y / b\n",
        "\n",
        "    rho = np.sqrt(x_norm**2 + y_norm**2)\n",
        "    theta = np.arctan2(y_norm, x_norm)\n",
        "\n",
        "    return rho, theta\n",
        "\n",
        "def parse_term_label(label):\n",
        "    \"\"\"\n",
        "    Parses different label styles into (func_name, k, n).\n",
        "    Supports:\n",
        "      - \"cos2_r^3\"          -> ('cos', 2, 3)\n",
        "      - \"sin1_r^0\"          -> ('sin', 1, 0)\n",
        "      - \"k1_cos_n2\"         -> ('cos', 1, 2)\n",
        "      - \"k0_cos_n0\"         -> ('cos', 0, 0)\n",
        "    \"\"\"\n",
        "    # Try format: k{K}_{cos|sin}_n{N}  (example file)\n",
        "    m = re.match(r'^k(?P<k>\\d+)_(?P<type>cos|sin)_n(?P<n>\\d+)$', label)\n",
        "    if m:\n",
        "        func_type = m.group('type')\n",
        "        k = int(m.group('k'))\n",
        "        n = int(m.group('n'))\n",
        "        return func_type, k, n\n",
        "\n",
        "    # Try old format: e.g., \"cos2_r^3\" or \"sin1_r^0\"\n",
        "    # allow \"cos2_r^3\", \"sin1_r^0\", maybe \"cos_r^2\" (no freq) etc.\n",
        "    try:\n",
        "        trig_part, rad_part = label.split('_', 1)\n",
        "    except ValueError:\n",
        "        raise ValueError(f\"Unrecognized term label format: {label}\")\n",
        "\n",
        "    # trig_part like 'cos2' or 'sin1' or 'cos'\n",
        "    m2 = re.match(r'^(cos|sin)(?P<k>\\d*)$', trig_part)\n",
        "    if not m2:\n",
        "        raise ValueError(f\"Unknown trig function in {label}\")\n",
        "\n",
        "    func_type = m2.group(1)\n",
        "    k_str = m2.group('k')\n",
        "    k = int(k_str) if k_str != '' else 1  # default freq 1 if omitted (safe fallback)\n",
        "\n",
        "    # rad_part expected like 'r^3' or 'r^0'\n",
        "    m3 = re.match(r'^r\\^(?P<n>\\d+)$', rad_part)\n",
        "    if not m3:\n",
        "        raise ValueError(f\"Unknown radial power format in {label}\")\n",
        "\n",
        "    n = int(m3.group('n'))\n",
        "\n",
        "    return func_type, k, n\n",
        "\n",
        "def find_json_file(filename):\n",
        "    \"\"\"\n",
        "    Try locating filename in common locations. Returns full path or None.\n",
        "    Looks in:\n",
        "      - absolute path if filename is absolute\n",
        "      - ./filename\n",
        "      - /mnt/data/filename\n",
        "      - /content/filename\n",
        "      - case-insensitive matches in /mnt/data and cwd (if exact not found)\n",
        "    \"\"\"\n",
        "    # if user passed absolute path\n",
        "    if os.path.isabs(filename) and os.path.exists(filename):\n",
        "        return filename\n",
        "\n",
        "    # try cwd\n",
        "    cwd_candidate = os.path.join(os.getcwd(), filename)\n",
        "    if os.path.exists(cwd_candidate):\n",
        "        return cwd_candidate\n",
        "\n",
        "    # /mnt/data (common for uploaded files)\n",
        "    mnt_candidate = os.path.join('/mnt/data', filename)\n",
        "    if os.path.exists(mnt_candidate):\n",
        "        return mnt_candidate\n",
        "\n",
        "    # /content (colab style)\n",
        "    content_candidate = os.path.join('/content', filename)\n",
        "    if os.path.exists(content_candidate):\n",
        "        return content_candidate\n",
        "\n",
        "    # try case-insensitive search in /mnt/data and cwd\n",
        "    for base in [os.getcwd(), '/mnt/data', '/content']:\n",
        "        if not os.path.isdir(base):\n",
        "            continue\n",
        "        try:\n",
        "            for fname in os.listdir(base):\n",
        "                if fname.lower() == filename.lower():\n",
        "                    return os.path.join(base, fname)\n",
        "        except PermissionError:\n",
        "            continue\n",
        "\n",
        "    return None\n",
        "\n",
        "def load_polynomial_distribution(filename, rho, theta, mask):\n",
        "    \"\"\"\n",
        "    Reconstructs the distribution from JSON coefficients.\n",
        "    Basis: coeff * trig(k*theta) * rho^n\n",
        "\n",
        "    Handles multiple JSON formats:\n",
        "      - {\"term_labels\": [...], \"coeffs\": [...]}\n",
        "      - {\"meta\": {\"term_order\": [...]}, \"coeffs\": [...]}\n",
        "      - Or other variants where 'term_labels' or 'term_order' are present.\n",
        "    \"\"\"\n",
        "    # locate file in common places (supports uploaded example in /mnt/data)\n",
        "    file_path = find_json_file(filename)\n",
        "    if file_path is None:\n",
        "        print(f\"Warning: {filename} not found in common locations. Returning uniform 0.\")\n",
        "        return np.zeros_like(rho)\n",
        "\n",
        "    # load JSON\n",
        "    try:\n",
        "        with open(file_path, 'r') as f:\n",
        "            data = json.load(f)\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading {file_path}: {e}\")\n",
        "        return np.zeros_like(rho)\n",
        "\n",
        "    # Determine label list\n",
        "    labels = None\n",
        "    if isinstance(data, dict):\n",
        "        if \"term_labels\" in data and isinstance(data[\"term_labels\"], list):\n",
        "            labels = data[\"term_labels\"]\n",
        "        elif \"term_order\" in data and isinstance(data[\"term_order\"], list):\n",
        "            labels = data[\"term_order\"]\n",
        "        elif \"meta\" in data and isinstance(data[\"meta\"], dict) and \"term_order\" in data[\"meta\"]:\n",
        "            labels = data[\"meta\"][\"term_order\"]\n",
        "        # some files might use \"labels\"\n",
        "        elif \"labels\" in data and isinstance(data[\"labels\"], list):\n",
        "            labels = data[\"labels\"]\n",
        "\n",
        "    coeffs = data.get(\"coeffs\", None)\n",
        "    if coeffs is None or labels is None:\n",
        "        print(f\"Error: {os.path.basename(file_path)} missing 'coeffs' or term label info. Returning zeros.\")\n",
        "        return np.zeros_like(rho)\n",
        "\n",
        "    # Ensure labels and coeffs align; if lengths mismatch, use minimal length and warn\n",
        "    if len(labels) != len(coeffs):\n",
        "        min_len = min(len(labels), len(coeffs))\n",
        "        if min_len == 0:\n",
        "            print(f\"Error: No usable terms in {os.path.basename(file_path)}. Returning zeros.\")\n",
        "            return np.zeros_like(rho)\n",
        "        print(f\"Warning: label/coeff length mismatch in {os.path.basename(file_path)} \"\n",
        "              f\"({len(labels)} labels, {len(coeffs)} coeffs). Truncating to {min_len}.\")\n",
        "        labels = labels[:min_len]\n",
        "        coeffs = coeffs[:min_len]\n",
        "\n",
        "    # Accumulate distribution\n",
        "    dist_map = np.zeros_like(rho, dtype=float)\n",
        "\n",
        "    for label, C in zip(labels, coeffs):\n",
        "        if C == 0:\n",
        "            continue\n",
        "\n",
        "        # parse label robustly (supports both styles)\n",
        "        try:\n",
        "            func_type, k, n = parse_term_label(label)\n",
        "        except ValueError as e:\n",
        "            # skip unknown labels but warn\n",
        "            print(f\"Warning: skipping term '{label}' due to parse error: {e}\")\n",
        "            continue\n",
        "\n",
        "        # radial power\n",
        "        radial_term = rho ** n\n",
        "\n",
        "        # angular term: handle k==0 properly (cos(0)=1, sin(0)=0)\n",
        "        if func_type == 'cos':\n",
        "            angular_term = np.cos(k * theta)\n",
        "        else:\n",
        "            angular_term = np.sin(k * theta)\n",
        "\n",
        "        dist_map += float(C) * angular_term * radial_term\n",
        "\n",
        "    # Mask outside points\n",
        "    dist_map[~mask] = 0.0\n",
        "\n",
        "    # Clip negative values if any (concentrations cannot be negative)\n",
        "    if np.any(dist_map[mask] < 0):\n",
        "        dist_map[dist_map < 0] = 0.0\n",
        "\n",
        "    return dist_map\n",
        "\n",
        "def normalize_to_total(dist_map, mask, target_avg_conc):\n",
        "    \"\"\"\n",
        "    Normalizes the distribution such that the average concentration\n",
        "    over the masked area equals target_avg_conc.\n",
        "    \"\"\"\n",
        "    current_avg = np.mean(dist_map[mask])\n",
        "    if current_avg == 0:\n",
        "        return dist_map\n",
        "    scale = target_avg_conc / current_avg\n",
        "    return dist_map * scale\n",
        "\n",
        "# ==============================================================================\n",
        "# 2. COMPUTE MAPS\n",
        "# ==============================================================================\n",
        "\n",
        "print(\"--- computing polynomial distributions ---\")\n",
        "\n",
        "# A. Coordinate Systems\n",
        "rho, theta = get_ellipse_coords(X, Y, a, b)\n",
        "\n",
        "# B. Map Enzymes E1, E2, E3\n",
        "targets = {\n",
        "    \"E1\": 60.9,\n",
        "    \"E2\": 64.7,\n",
        "    \"E3\": 15.8\n",
        "}\n",
        "\n",
        "maps = {}\n",
        "\n",
        "for name, target_conc in targets.items():\n",
        "    filename = f\"{name}_eqn.json\"\n",
        "    print(f\"Processing {filename}...\")\n",
        "\n",
        "    # 1. Reconstruct raw shape from coefficients\n",
        "    raw_dist = load_polynomial_distribution(filename, rho, theta, mask)\n",
        "\n",
        "    # 2. Normalize to meet the 'Total Concentration' requirement\n",
        "    # (Interpreted as global average concentration)\n",
        "    maps[name] = normalize_to_total(raw_dist, mask, target_conc)\n",
        "\n",
        "# C. Map Substrate (Uniform throughout cell)\n",
        "# Defined: 134 uM, spread uniformly across the cell interior (mask)\n",
        "print(\"Processing Substrate (uniform throughout cell)...\")\n",
        "target_S_conc = 134.0\n",
        "\n",
        "# Create uniform substrate within the mask\n",
        "S_map = np.zeros_like(X)\n",
        "S_map[mask] = 1.0\n",
        "\n",
        "# Normalize substrate to desired average inside mask\n",
        "maps[\"Substrate\"] = normalize_to_total(S_map, mask, target_S_conc)\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# 3. VISUALIZATION\n",
        "# ==============================================================================\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "fig.suptitle(\"Initial Concentration Distributions (µM)\", fontsize=16)\n",
        "\n",
        "plot_list = [\n",
        "    (\"E1\", maps[\"E1\"], axes[0,0]),\n",
        "    (\"E2\", maps[\"E2\"], axes[0,1]),\n",
        "    (\"E3\", maps[\"E3\"], axes[1,0]),\n",
        "    (\"Substrate\", maps[\"Substrate\"], axes[1,1])\n",
        "]\n",
        "\n",
        "for name, data, ax in plot_list:\n",
        "    # Plot masked array\n",
        "    masked_data = np.ma.masked_where(~mask, data)\n",
        "\n",
        "    # Dynamic coloring based on range inside mask\n",
        "    vmin = data[mask].min()\n",
        "    vmax = data[mask].max()\n",
        "\n",
        "    pcm = ax.pcolormesh(X, Y, masked_data, shading='auto', cmap='viridis', vmin=vmin, vmax=vmax)\n",
        "\n",
        "    avg_val = np.mean(data[mask])\n",
        "    ax.set_title(f\"{name} Distribution\\nMean: {avg_val:.1f} µM\")\n",
        "    ax.set_aspect('equal')\n",
        "    ax.set_xlabel('x (µm)')\n",
        "    ax.set_ylabel('y (µm)')\n",
        "\n",
        "    # Draw boundary\n",
        "    th_plot = np.linspace(0, 2*np.pi, 200)\n",
        "    ax.plot(a*np.cos(th_plot), b*np.sin(th_plot), 'k--', lw=1, alpha=0.5)\n",
        "\n",
        "    fig.colorbar(pcm, ax=ax, label='Concentration (µM)')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.subplots_adjust(top=0.92)\n",
        "plt.show()\n",
        "\n",
        "# ==============================================================================\n",
        "# 4. EXPORT FOR FTCS\n",
        "# ==============================================================================\n",
        "# Save these maps to a dictionary 'concentration_maps' for the next step\n",
        "concentration_maps = maps\n",
        "\n",
        "print(\"\\n--- Validation ---\")\n",
        "for k, v in maps.items():\n",
        "    print(f\"{k} Global Average: {np.mean(v[mask]):.2f} µM (Target: {targets.get(k, target_S_conc)})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OtTFAYtaLqBh"
      },
      "outputs": [],
      "source": [
        "import matplotlib.patches as mpatches\n",
        "\n",
        "# ==============================================================================\n",
        "# VISUALIZATION: HIGH CONCENTRATION ZONES (HOTSPOTS)\n",
        "# ==============================================================================\n",
        "\n",
        "def plot_hotspots(concentration_maps, X, Y, mask, a, b):\n",
        "    \"\"\"\n",
        "    Visualizes regions where concentration exceeds 90%, 95%, and 99%\n",
        "    of the global maximum for each enzyme.\n",
        "    \"\"\"\n",
        "    enzymes = ['E1', 'E2', 'E3']\n",
        "\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "    fig.suptitle(\"High Concentration Zones (>90%, >95%, >99% of Peak Molarity)\", fontsize=16)\n",
        "\n",
        "    # Define colors for the thresholds\n",
        "    # 90-95% (Yellow), 95-99% (Orange), 99-100% (Red)\n",
        "    colors = ['#FFEDA0', '#FEB24C', '#F03B20']\n",
        "    labels = ['Top 10% (>0.90 max)', 'Top 5% (>0.95 max)', 'Top 1% (>0.99 max)']\n",
        "\n",
        "    for i, name in enumerate(enzymes):\n",
        "        ax = axes[i]\n",
        "        data = concentration_maps[name]\n",
        "\n",
        "        # 1. Determine the Peak Concentration (C_max)\n",
        "        # We only consider points inside the ellipse\n",
        "        valid_data = data[mask]\n",
        "        c_max = valid_data.max()\n",
        "\n",
        "        # 2. Define contour levels relative to C_max\n",
        "        levels = [0.90 * c_max, 0.95 * c_max, 0.99 * c_max, c_max * 1.001]\n",
        "\n",
        "        # 3. Plot the ellipse boundary (context)\n",
        "        theta_plot = np.linspace(0, 2*np.pi, 200)\n",
        "        ax.plot(a*np.cos(theta_plot), b*np.sin(theta_plot), 'k--', lw=1, alpha=0.3)\n",
        "\n",
        "        # 4. Fill the contours\n",
        "        # We mask the data again just to be safe for the plot\n",
        "        data_masked = np.ma.masked_where(~mask, data)\n",
        "\n",
        "        # Contourf fills intervals: [0.90, 0.95), [0.95, 0.99), [0.99, Max]\n",
        "        cs = ax.contourf(X, Y, data_masked, levels=levels, colors=colors, extend='max')\n",
        "\n",
        "        # 5. Aesthetics\n",
        "        ax.set_title(f\"{name} Peak Zones\\n($C_{{max}}$ = {c_max:.2f} µM)\")\n",
        "        ax.set_aspect('equal')\n",
        "        ax.set_xlabel('x (µm)')\n",
        "        ax.set_ylabel('y (µm)')\n",
        "        ax.grid(True, which='both', linestyle=':', alpha=0.3)\n",
        "\n",
        "        # 6. Custom Legend\n",
        "        patches = [mpatches.Patch(color=colors[j], label=labels[j]) for j in range(3)]\n",
        "        # Add a patch for the background (rest of cell)\n",
        "        patches.insert(0, mpatches.Patch(color='white', label='< 90% of max', ec='lightgray'))\n",
        "        ax.legend(handles=patches, loc='upper right', fontsize='small', framealpha=0.9)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.subplots_adjust(top=0.85)\n",
        "    plt.show()\n",
        "\n",
        "# Run the visualization\n",
        "plot_hotspots(concentration_maps, X, Y, mask, a, b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "MVHe7grjLuYp"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from matplotlib.animation import PillowWriter\n",
        "from numba import njit\n",
        "from tqdm.notebook import tqdm\n",
        "import scipy.ndimage as nd\n",
        "import matplotlib.ticker as mticker\n",
        "\n",
        "# ======================================================================\n",
        "# ASSUMPTION: the following names exist in your notebook environment:\n",
        "# mask (2D boolean), X, Y (2D coordinate grids), a, b, dx, concentration_maps\n",
        "# ======================================================================\n",
        "\n",
        "# -------------------\n",
        "# 1. HELPER FUNCTIONS\n",
        "# -------------------\n",
        "\n",
        "def add_padding(arr):\n",
        "    return np.pad(arr, pad_width=1, mode='constant', constant_values=0)\n",
        "\n",
        "def remove_padding(arr):\n",
        "    return arr[1:-1, 1:-1]\n",
        "\n",
        "def create_spread_random(mask, total_mass, sigma=1, seed=None):\n",
        "    \"\"\"\n",
        "    Creates a spread-out random distribution across the mask while conserving mass.\n",
        "    \"\"\"\n",
        "    if seed is not None:\n",
        "        rs = np.random.RandomState(seed)\n",
        "        noise = rs.rand(*mask.shape)\n",
        "    else:\n",
        "        noise = np.random.rand(*mask.shape)\n",
        "\n",
        "    noise[~mask] = 0.0\n",
        "    noise = nd.gaussian_filter(noise, sigma=sigma)\n",
        "    noise[~mask] = 0.0\n",
        "\n",
        "    current_mass = np.sum(noise)\n",
        "    if current_mass > 0:\n",
        "        noise *= (total_mass / current_mass)\n",
        "    else:\n",
        "        noise[mask] = total_mass / np.count_nonzero(mask)\n",
        "\n",
        "    return noise\n",
        "\n",
        "def diffuse_enzyme_via_gaussian(E_padded, D, delta_t, dx, mask):\n",
        "    \"\"\"\n",
        "    Approximate solution of dE/dt = D ∇^2 E over time delta_t using a Gaussian blur,\n",
        "    conserving total mass within the mask.\n",
        "    \"\"\"\n",
        "    E = remove_padding(E_padded)\n",
        "    mass_before = np.sum(E[mask])\n",
        "    if mass_before == 0:\n",
        "        return E_padded\n",
        "\n",
        "    # sigma in grid units: sqrt(2*D*delta_t) / dx\n",
        "    sigma_pixels = np.sqrt(max(0.0, 2.0 * D * max(1e-16, delta_t))) / dx\n",
        "    if sigma_pixels <= 0.001:\n",
        "        return E_padded\n",
        "\n",
        "    E_blurred = nd.gaussian_filter(E, sigma=sigma_pixels)\n",
        "    E_blurred[~mask] = 0.0\n",
        "\n",
        "    mass_after = np.sum(E_blurred[mask])\n",
        "    if mass_after > 0:\n",
        "        E_blurred *= (mass_before / mass_after)\n",
        "    else:\n",
        "        E_blurred[mask] = mass_before / np.count_nonzero(mask)\n",
        "\n",
        "    return add_padding(E_blurred)\n",
        "\n",
        "# ------------------------------\n",
        "# 2. PREPARE MAPS FOR 3 SCENARIOS\n",
        "# ------------------------------\n",
        "\n",
        "S_raw = concentration_maps['Substrate'].copy()\n",
        "\n",
        "# Fix substrate rim if empty (as before)\n",
        "if np.sum(S_raw) == 0:\n",
        "    struct = nd.generate_binary_structure(2, 1)\n",
        "    mask_rim = mask ^ nd.binary_erosion(mask, structure=struct, iterations=1)\n",
        "    S_raw[:] = 0; S_raw[mask_rim] = 1.0\n",
        "    S_raw *= (134.0 / np.mean(S_raw[mask]))\n",
        "\n",
        "# Originals\n",
        "E1_orig = concentration_maps['E1'].copy()\n",
        "E2_orig = concentration_maps['E2'].copy()\n",
        "E3_orig = concentration_maps['E3'].copy()\n",
        "\n",
        "mass_E1 = np.sum(E1_orig[mask])\n",
        "mass_E2 = np.sum(E2_orig[mask])\n",
        "mass_E3 = np.sum(E3_orig[mask])\n",
        "\n",
        "# Randomized counterpart for E3 (used in case 3)\n",
        "E3_rand = create_spread_random(mask, mass_E3, sigma=2, seed=103)\n",
        "\n",
        "# --- Build concentric overlapping rings for E1 & E2 near the membrane\n",
        "# Center coordinates (robust)\n",
        "xc = 0.5 * (X.min() + X.max())\n",
        "yc = 0.5 * (Y.min() + Y.max())\n",
        "\n",
        "# normalized radius relative to cell ellipse (uses provided a,b)\n",
        "r_norm = np.sqrt(((X - xc) / (a + 1e-12))**2 + ((Y - yc) / (b + 1e-12))**2)\n",
        "\n",
        "# Design two slightly different thin ring windows so they are concentric and overlap\n",
        "# E1: slightly wider inner ring, E2: slightly narrower inner ring (both hugging membrane)\n",
        "e1_inner = 0.88\n",
        "e1_outer = 0.995\n",
        "e2_inner = 0.90\n",
        "e2_outer = 0.995\n",
        "\n",
        "E1_ring = np.zeros_like(E1_orig)\n",
        "E2_ring = np.zeros_like(E2_orig)\n",
        "\n",
        "e1_mask = (r_norm >= e1_inner) & (r_norm <= e1_outer) & mask\n",
        "e2_mask = (r_norm >= e2_inner) & (r_norm <= e2_outer) & mask\n",
        "\n",
        "# fallback widen if masks are empty\n",
        "if np.count_nonzero(e1_mask) == 0:\n",
        "    e1_mask = (r_norm >= 0.85) & (r_norm <= 1.0) & mask\n",
        "if np.count_nonzero(e2_mask) == 0:\n",
        "    e2_mask = (r_norm >= 0.85) & (r_norm <= 1.0) & mask\n",
        "\n",
        "if np.count_nonzero(e1_mask) > 0:\n",
        "    E1_ring[e1_mask] = 1.0\n",
        "    # conserve E1 mass\n",
        "    s = np.sum(E1_ring[mask])\n",
        "    if s > 0:\n",
        "        E1_ring *= (mass_E1 / s)\n",
        "else:\n",
        "    E1_ring = E1_orig.copy()\n",
        "\n",
        "if np.count_nonzero(e2_mask) > 0:\n",
        "    E2_ring[e2_mask] = 1.0\n",
        "    # conserve E2 mass\n",
        "    s2 = np.sum(E2_ring[mask])\n",
        "    if s2 > 0:\n",
        "        E2_ring *= (mass_E2 / s2)\n",
        "else:\n",
        "    E2_ring = E2_orig.copy()\n",
        "\n",
        "# E3 pole clusters (two small clusters near +/- x-axis ends) - unchanged\n",
        "cluster_radius = 0.05 * max(a, b)\n",
        "cluster1_center = (xc + 0.9 * a, yc)\n",
        "cluster2_center = (xc - 0.9 * a, yc)\n",
        "\n",
        "dist1 = np.sqrt((X - cluster1_center[0])**2 + (Y - cluster1_center[1])**2)\n",
        "dist2 = np.sqrt((X - cluster2_center[0])**2 + (Y - cluster2_center[1])**2)\n",
        "\n",
        "cluster_mask = ((dist1 <= cluster_radius) | (dist2 <= cluster_radius)) & mask\n",
        "E3_clusters = np.zeros_like(E3_orig)\n",
        "if np.count_nonzero(cluster_mask) > 0:\n",
        "    E3_clusters[cluster_mask] = 1.0\n",
        "    E3_clusters = nd.gaussian_filter(E3_clusters, sigma=1)\n",
        "    E3_clusters[~mask] = 0.0\n",
        "    if np.sum(E3_clusters[mask]) > 0:\n",
        "        E3_clusters *= (mass_E3 / np.sum(E3_clusters[mask]))\n",
        "    else:\n",
        "        E3_clusters = create_spread_random(mask, mass_E3, sigma=1, seed=104)\n",
        "else:\n",
        "    E3_clusters = create_spread_random(mask, mass_E3, sigma=1, seed=104)\n",
        "\n",
        "# Case definitions (only 3 now)\n",
        "# Use E1_ring and E2_ring (concentric overlapping rings) for E1 and E2 in ALL cases\n",
        "Case1_E1, Case1_E2, Case1_E3 = E1_ring.copy(), E2_ring.copy(), E3_orig.copy()\n",
        "Case2_E1, Case2_E2, Case2_E3 = E1_ring.copy(), E2_ring.copy(), E3_clusters.copy()\n",
        "Case3_E1, Case3_E2, Case3_E3 = E1_ring.copy(), E2_ring.copy(), E3_rand.copy()\n",
        "\n",
        "# diffusion flags per case (only E3 diffused in case 3)\n",
        "Diff_case1 = (False, False, False)\n",
        "Diff_case2 = (False, False, False)\n",
        "Diff_case3 = (False, False, True)\n",
        "\n",
        "# ------------------------------\n",
        "# 3. VISUALIZE INITIAL CONFIGS (3 rows)\n",
        "# ------------------------------\n",
        "\n",
        "fig, axes = plt.subplots(3, 3, figsize=(12, 11))\n",
        "fig.suptitle(\"Initial Enzyme Configurations (Mass Conserved) — 3 scenarios\", fontsize=14, y=0.95)\n",
        "\n",
        "scenarios_viz = [\n",
        "    (\"Case 1: rings (E1/E2) + E3 original\",    Case1_E1, Case1_E2, Case1_E3),\n",
        "    (\"Case 2: rings (E1/E2) + E3 poles\", Case2_E1, Case2_E2, Case2_E3),\n",
        "    (\"Case 3: rings (E1/E2) + E3 random\", Case3_E1, Case3_E2, Case3_E3)\n",
        "]\n",
        "\n",
        "cols = [\"E1\", \"E2\", \"E3\"]\n",
        "\n",
        "for i, (title, e1, e2, e3) in enumerate(scenarios_viz):\n",
        "    maps_row = [e1, e2, e3]\n",
        "    axes[i, 0].set_ylabel(title, fontsize=10, rotation=90, labelpad=20)\n",
        "    for j, m in enumerate(maps_row):\n",
        "        masked = np.ma.masked_where(~mask, m)\n",
        "        pcm = axes[i, j].pcolormesh(X, Y, masked, shading='auto', cmap='viridis')\n",
        "        if i == 0:\n",
        "            axes[i, j].set_title(cols[j], fontsize=12)\n",
        "        axes[i, j].axis('off')\n",
        "        th = np.linspace(0, 2*np.pi, 200)\n",
        "        axes[i, j].plot(a*np.cos(th), b*np.sin(th), 'k-', lw=0.5, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ------------------------------\n",
        "# Substrate map visualization (unchanged)\n",
        "# ------------------------------\n",
        "plt.figure(figsize=(6, 5))\n",
        "masked_S = np.ma.masked_where(~mask, S_raw)\n",
        "if np.count_nonzero(mask) > 0:\n",
        "    vmin = S_raw[mask].min()\n",
        "    vmax = S_raw[mask].max()\n",
        "else:\n",
        "    vmin, vmax = 0.0, 1.0\n",
        "pcm_s = plt.pcolormesh(X, Y, masked_S, shading='auto', cmap='Blues', vmin=vmin, vmax=vmax)\n",
        "plt.colorbar(pcm_s, label='Substrate (µM)')\n",
        "plt.title(\"Initial Substrate Distribution\")\n",
        "th_plot = np.linspace(0, 2*np.pi, 200)\n",
        "plt.plot(a*np.cos(th_plot), b*np.sin(th_plot), 'k--', lw=1, alpha=0.5)\n",
        "plt.gca().set_aspect('equal')\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "# ------------------------------\n",
        "\n",
        "# --------------------------------------\n",
        "# 4. SIMULATION CONSTANTS & ROBUST DT\n",
        "# --------------------------------------\n",
        "\n",
        "# Run until steady-state (or until max_time)\n",
        "total_time = 20          # maximum seconds (upper cap)\n",
        "snapshot_interval = 0.01  # seconds\n",
        "num_snapshots = int(total_time / snapshot_interval)\n",
        "\n",
        "# Small-molecule diffusion (set to 10 as requested)\n",
        "D_S, D_I1, D_I2, D_P = 0.01, 0.01, 0.01, 0.01\n",
        "\n",
        "# Enzyme diffusion: only E3 may diffuse (case 3) - default zero\n",
        "D_E1, D_E2, D_E3_default = 0.0, 0.0, 0.0\n",
        "D_E3_case3 = 1e-2  # for case 3 only\n",
        "\n",
        "k_cat1 = 0.93 / 60.0\n",
        "k_cat2 = 12.02 / 60.0\n",
        "k_cat3 = 1.08 / 60.0\n",
        "Km1, Km2, Km3 = 1.11, 4.50, 0.94\n",
        "\n",
        "if 'dx' not in globals():\n",
        "    raise RuntimeError(\"dx not defined.\")\n",
        "if dx <= 0:\n",
        "    raise ValueError(\"dx must be > 0.\")\n",
        "\n",
        "all_D_small = [D_S, D_I1, D_I2, D_P]\n",
        "max_D_small = max([float(d) if d is not None else 0.0 for d in all_D_small])\n",
        "dt_stability = (0.25 * dx**2) / max_D_small\n",
        "dt = dt_stability * 0.00009\n",
        "if dt <= 0: dt = 1e-12\n",
        "\n",
        "steps_per_chunk = int(round(snapshot_interval / dt))\n",
        "if steps_per_chunk < 1: steps_per_chunk = 1\n",
        "\n",
        "mask_int = add_padding(mask).astype(np.int32)\n",
        "S_pad = add_padding(S_raw)\n",
        "ny, nx = S_pad.shape\n",
        "n_pixels = np.count_nonzero(mask)\n",
        "pixel_area = dx * dx\n",
        "total_area = n_pixels * pixel_area\n",
        "\n",
        "print(f\"[solver] dx={dx:.3e}, dt={dt:.3e}, steps_per_chunk={steps_per_chunk}, num_snapshots={num_snapshots}\")\n",
        "\n",
        "# -----------------------\n",
        "# 5. NUMBA SOLVER (w/ leakage tracking, absolute mass)\n",
        "# -----------------------\n",
        "\n",
        "# fraction of product crossing membrane that is lost to outside (70% leak)\n",
        "LEAK_FRACTION = 0.7\n",
        "\n",
        "@njit(fastmath=True)\n",
        "def run_simulation(S, I1, I2, P, E1, E2, E3, mask_int, dx, dt, steps, leak_frac):\n",
        "    \"\"\"\n",
        "    Returns S,I1,I2,P and (production_total_mass, leaked_mass_estimate)\n",
        "    Units: \"mass units\" = concentration * pixel area (dx*dx).\n",
        "    \"\"\"\n",
        "    ny, nx = S.shape\n",
        "\n",
        "    alpha_S = D_S * dt / dx**2\n",
        "    alpha_I1 = D_I1 * dt / dx**2\n",
        "    alpha_I2 = D_I2 * dt / dx**2\n",
        "    alpha_P = D_P * dt / dx**2\n",
        "\n",
        "    production_total_mass = 0.0\n",
        "    leaked_total_mass = 0.0\n",
        "\n",
        "    S_n = S.copy(); I1_n = I1.copy(); I2_n = I2.copy(); P_n = P.copy()\n",
        "\n",
        "    # pixel area for mass conversion\n",
        "    pix_area = dx * dx\n",
        "\n",
        "    for _ in range(steps):\n",
        "        for y in range(1, ny-1):\n",
        "            for x in range(1, nx-1):\n",
        "                if mask_int[y, x] == 1:\n",
        "                    s = S[y,x]; i1 = I1[y,x]; i2 = I2[y,x]; p = P[y,x]\n",
        "\n",
        "                    # S neighbors (Neumann-like reflective within mask) -> no flux to outside\n",
        "                    s_u = S[y-1,x] if mask_int[y-1,x] else s\n",
        "                    s_d = S[y+1,x] if mask_int[y+1,x] else s\n",
        "                    s_l = S[y,x-1] if mask_int[y,x-1] else s\n",
        "                    s_r = S[y,x+1] if mask_int[y,x+1] else s\n",
        "\n",
        "                    # I1 neighbors (reflective)\n",
        "                    i1_u = I1[y-1,x] if mask_int[y-1,x] else i1\n",
        "                    i1_d = I1[y+1,x] if mask_int[y+1,x] else i1\n",
        "                    i1_l = I1[y,x-1] if mask_int[y,x-1] else i1\n",
        "                    i1_r = I1[y,x+1] if mask_int[y,x+1] else i1\n",
        "\n",
        "                    # I2 neighbors (reflective)\n",
        "                    i2_u = I2[y-1,x] if mask_int[y-1,x] else i2\n",
        "                    i2_d = I2[y+1,x] if mask_int[y+1,x] else i2\n",
        "                    i2_l = I2[y,x-1] if mask_int[y,x-1] else i2\n",
        "                    i2_r = I2[y,x+1] if mask_int[y,x+1] else i2\n",
        "\n",
        "                    # P neighbors: if neighbor outside mask -> reduced neighbor (simulates loss)\n",
        "                    # Also estimate leakage: for each outside neighbor we add approx. alpha_P * leak_frac * p (mass lost)\n",
        "                    if mask_int[y-1,x]:\n",
        "                        p_u = P[y-1,x]\n",
        "                    else:\n",
        "                        p_u = p * (1.0 - leak_frac)\n",
        "                        leaked_total_mass += alpha_P * leak_frac * p * pix_area\n",
        "\n",
        "                    if mask_int[y+1,x]:\n",
        "                        p_d = P[y+1,x]\n",
        "                    else:\n",
        "                        p_d = p * (1.0 - leak_frac)\n",
        "                        leaked_total_mass += alpha_P * leak_frac * p * pix_area\n",
        "\n",
        "                    if mask_int[y,x-1]:\n",
        "                        p_l = P[y,x-1]\n",
        "                    else:\n",
        "                        p_l = p * (1.0 - leak_frac)\n",
        "                        leaked_total_mass += alpha_P * leak_frac * p * pix_area\n",
        "\n",
        "                    if mask_int[y,x+1]:\n",
        "                        p_r = P[y,x+1]\n",
        "                    else:\n",
        "                        p_r = p * (1.0 - leak_frac)\n",
        "                        leaked_total_mass += alpha_P * leak_frac * p * pix_area\n",
        "\n",
        "                    # Enzymes at this cell\n",
        "                    e1 = E1[y,x]\n",
        "                    e2 = E2[y,x]\n",
        "                    e3 = E3[y,x]\n",
        "\n",
        "                    # Reaction rates (concentration/time). mass produced in dt = r3 * dt * pixel_area\n",
        "                    r1 = (k_cat1 * e1 * s)  / (Km1 + s + 1e-12)\n",
        "                    r2 = (k_cat2 * e2 * i1) / (Km2 + i1 + 1e-12)\n",
        "                    r3 = (k_cat3 * e3 * i2) / (Km3 + i2 + 1e-12)\n",
        "\n",
        "                    production_total_mass += r3 * dt * pix_area\n",
        "\n",
        "                    # Update via explicit finite-difference (diffusion + reaction)\n",
        "                    S_n[y,x]  = s  + alpha_S  * (s_u + s_d + s_l + s_r - 4.0*s)  - r1 * dt\n",
        "                    I1_n[y,x] = i1 + alpha_I1 * (i1_u + i1_d + i1_l + i1_r - 4.0*i1) + (r1 - r2) * dt\n",
        "                    I2_n[y,x] = i2 + alpha_I2 * (i2_u + i2_d + i2_l + i2_r - 4.0*i2) + (r2 - r3) * dt\n",
        "                    P_n[y,x]  = p  + alpha_P  * (p_u + p_d + p_l + p_r - 4.0*p)  + r3 * dt\n",
        "\n",
        "        # Commit updates (in-place swap)\n",
        "        for y in range(1, ny-1):\n",
        "            for x in range(1, nx-1):\n",
        "                if mask_int[y,x] == 1:\n",
        "                    S[y,x], I1[y,x], I2[y,x], P[y,x] = S_n[y,x], I1_n[y,x], I2_n[y,x], P_n[y,x]\n",
        "\n",
        "    return S, I1, I2, P, production_total_mass, leaked_total_mass\n",
        "\n",
        "# -----------------------\n",
        "# 6. EXECUTION LOOP (keeps flow similar to original)\n",
        "# -----------------------\n",
        "\n",
        "def run_scenario(E1_in, E2_in, E3_in, label, diff_flags=(False, False, False), D_E3_param=0.0):\n",
        "    \"\"\"\n",
        "    Run simulation for one scenario.\n",
        "    diff_flags: tuple of booleans (diffuse_E1, diffuse_E2, diffuse_E3)\n",
        "    D_E3_param: diffusion coefficient for E3 (used only if diff_flags[2] is True)\n",
        "    \"\"\"\n",
        "    S_curr  = S_pad.copy()\n",
        "    I1_curr = np.zeros_like(S_pad)\n",
        "    I2_curr = np.zeros_like(S_pad)\n",
        "    P_curr  = np.zeros_like(S_pad)\n",
        "\n",
        "    E1_p = add_padding(E1_in)\n",
        "    E2_p = add_padding(E2_in)\n",
        "    E3_p = add_padding(E3_in)\n",
        "\n",
        "    # Warmup\n",
        "    _ = run_simulation(S_curr.copy(), I1_curr.copy(), I2_curr.copy(), P_curr.copy(),\n",
        "                       E1_p, E2_p, E3_p, mask_int, dx, dt, 10, LEAK_FRACTION)\n",
        "\n",
        "    hist = {'time': [], 'S': [], 'I1': [], 'I2': [], 'P': [], 'P_total': [],   # P_total is ABSOLUTE mass now\n",
        "            'P_leaked': [], 'P_leaked_cum': []}\n",
        "\n",
        "    d_e1, d_e2, d_e3 = diff_flags\n",
        "    cum_leaked = 0.0\n",
        "\n",
        "    for i in tqdm(range(num_snapshots), desc=label):\n",
        "        S_curr, I1_curr, I2_curr, P_curr, prod_mass_chunk, leaked_mass_chunk = run_simulation(\n",
        "            S_curr, I1_curr, I2_curr, P_curr,\n",
        "            E1_p, E2_p, E3_p, mask_int, dx, dt, steps_per_chunk, LEAK_FRACTION\n",
        "        )\n",
        "\n",
        "        cum_leaked += leaked_mass_chunk\n",
        "\n",
        "        # Apply enzyme diffusion (coarse-grained per snapshot interval)\n",
        "        if d_e1:\n",
        "            E1_p = diffuse_enzyme_via_gaussian(E1_p, D_E1, snapshot_interval, dx, mask)\n",
        "        if d_e2:\n",
        "            E2_p = diffuse_enzyme_via_gaussian(E2_p, D_E2, snapshot_interval, dx, mask)\n",
        "        if d_e3:\n",
        "            E3_p = diffuse_enzyme_via_gaussian(E3_p, D_E3_param, snapshot_interval, dx, mask)\n",
        "\n",
        "        t_val = (i+1) * snapshot_interval\n",
        "        hist['time'].append(t_val)\n",
        "        hist['S'].append(remove_padding(S_curr).copy())\n",
        "        hist['I1'].append(remove_padding(I1_curr).copy())\n",
        "        hist['I2'].append(remove_padding(I2_curr).copy())\n",
        "        hist['P'].append(remove_padding(P_curr).copy())\n",
        "\n",
        "        # total product mass inside cell = sum(conc * pixel_area)\n",
        "        P_total_mass = np.sum(remove_padding(P_curr)) * (dx * dx)\n",
        "        hist['P_total'].append(P_total_mass)\n",
        "\n",
        "        hist['P_leaked'].append(leaked_mass_chunk)\n",
        "        hist['P_leaked_cum'].append(cum_leaked)\n",
        "\n",
        "        # --- early stop: steady-state criterion on P_total ---\n",
        "        if i > 20:\n",
        "            prev_idx = max(0, i - 20)\n",
        "            prev_val = hist['P_total'][prev_idx]\n",
        "            cur_val = hist['P_total'][-1]\n",
        "            # relative change over last window\n",
        "            rel_change = abs(cur_val - prev_val) / (abs(prev_val) + 1e-12)\n",
        "            if rel_change < 1e-4:\n",
        "                print(f\"[{label}] steady-state reached at t={t_val:.4f}s (rel change {rel_change:.2e}) after {i+1} snapshots\")\n",
        "                break\n",
        "\n",
        "    return hist\n",
        "\n",
        "# Run the three scenarios (Case 3 uses E3 diffusion coef)\n",
        "Hist_C1 = run_scenario(Case1_E1, Case1_E2, Case1_E3, \"Case 1 (rings + E3 original)\", Diff_case1, D_E3_param=D_E3_default)\n",
        "Hist_C2 = run_scenario(Case2_E1, Case2_E2, Case2_E3, \"Case 2 (rings + E3 poles)\", Diff_case2, D_E3_param=D_E3_default)\n",
        "Hist_C3 = run_scenario(Case3_E1, Case3_E2, Case3_E3, \"Case 3 (rings + E3 random + E3 diff)\", Diff_case3, D_E3_param=D_E3_case3)\n",
        "\n",
        "# -----------------------\n",
        "# 7. COMPARATIVE ANALYSIS (focus on leaked P)\n",
        "# -----------------------\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# pick a reference time series (they might have different lengths due to early stopping)\n",
        "times_s = Hist_C1['time']\n",
        "if len(times_s) == 0:\n",
        "    raise RuntimeError(\"Case 1 produced no history (zero snapshots). Check settings.\")\n",
        "\n",
        "# Ensure we have same length arrays for simple plotting - choose length of smallest run\n",
        "min_len = min(len(Hist_C1['P_total']), len(Hist_C2['P_total']), len(Hist_C3['P_total']))\n",
        "times_ms = [t*1000.0 for t in Hist_C1['time'][:min_len]]\n",
        "\n",
        "# inside average concentration (µM) = (total mass) / (total area)\n",
        "avg_C1_in = [val / (n_pixels * dx * dx) for val in Hist_C1['P_total'][:min_len]]\n",
        "avg_C2_in = [val / (n_pixels * dx * dx) for val in Hist_C2['P_total'][:min_len]]\n",
        "avg_C3_in = [val / (n_pixels * dx * dx) for val in Hist_C3['P_total'][:min_len]]\n",
        "\n",
        "# leaked cumulative (absolute mass)\n",
        "leak_C1 = Hist_C1['P_leaked_cum'][:min_len]\n",
        "leak_C2 = Hist_C2['P_leaked_cum'][:min_len]\n",
        "leak_C3 = Hist_C3['P_leaked_cum'][:min_len]\n",
        "\n",
        "# Plot inside product (avg µM)\n",
        "plt.plot(times_ms, avg_C1_in, 'k-', linewidth=2.0, label='Case 1: inside P (avg µM)')\n",
        "plt.plot(times_ms, avg_C2_in, 'b--', linewidth=2.0, label='Case 2: inside P (avg µM)')\n",
        "plt.plot(times_ms, avg_C3_in, 'g--', linewidth=2.0, label='Case 3: inside P (avg µM)')\n",
        "\n",
        "plt.title(\"Inside Product (avg µM) vs Time — compare cases\", fontsize=14)\n",
        "plt.xlabel(\"Time (ms)\", fontsize=12)\n",
        "plt.ylabel(\"Average Concentration (µM)\", fontsize=12)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.legend(fontsize=9)\n",
        "\n",
        "# tidy ticks\n",
        "max_ms = max(times_ms) if len(times_ms) else total_time*1000.0\n",
        "xticks = np.linspace(0.0, max_ms, num=6)\n",
        "plt.gca().xaxis.set_major_locator(mticker.FixedLocator(xticks))\n",
        "plt.gca().xaxis.set_major_formatter(mticker.FormatStrFormatter('%.1f'))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Plot leaked cumulative (absolute mass units = conc * pixel_area)\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(times_ms, leak_C1, 'k-', linewidth=2.0, label='Case 1 leaked (cum, mass units)')\n",
        "plt.plot(times_ms, leak_C2, 'b--', linewidth=2.0, label='Case 2 leaked (cum, mass units)')\n",
        "plt.plot(times_ms, leak_C3, 'g--', linewidth=2.0, label='Case 3 leaked (cum, mass units)')\n",
        "plt.title(\"Cumulative Product Leaked Outside vs Time\", fontsize=14)\n",
        "plt.xlabel(\"Time (ms)\", fontsize=12)\n",
        "plt.ylabel(\"Cumulative Leaked Product (mass units = conc × pixel_area)\", fontsize=12)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.legend(fontsize=9)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Summary stats (final inside & leaked)\n",
        "final_in_1 = avg_C1_in[-1]; final_in_2 = avg_C2_in[-1]; final_in_3 = avg_C3_in[-1]\n",
        "final_leak_1 = leak_C1[-1]; final_leak_2 = leak_C2[-1]; final_leak_3 = leak_C3[-1]\n",
        "\n",
        "print(\"\\nFinal summary (inside avg conc µM, leaked cumulative mass):\")\n",
        "print(f\"Case1: inside final avg µM = {final_in_1:.4e}, leaked total mass = {final_leak_1:.4e}\")\n",
        "print(f\"Case2: inside final avg µM = {final_in_2:.4e}, leaked total mass = {final_leak_2:.4e}\")\n",
        "print(f\"Case3: inside final avg µM = {final_in_3:.4e}, leaked total mass = {final_leak_3:.4e}\")\n",
        "\n",
        "# -----------------------\n",
        "# 8. GENERATE GIFs (adds leaked cumulative to P GIF titles)\n",
        "# -----------------------\n",
        "\n",
        "def save_gif(data_list, time_list, filename, title_prefix, cmap, vmax=None, leak_list=None):\n",
        "    print(f\"Generating {filename}...\")\n",
        "    fig, ax = plt.subplots(figsize=(5, 3))\n",
        "\n",
        "    if vmax is None:\n",
        "        # protect against empty arrays\n",
        "        vmax_candidate = 0.0\n",
        "        for d in data_list:\n",
        "            if np.count_nonzero(d[mask]) > 0:\n",
        "                vmax_candidate = max(vmax_candidate, d[mask].max())\n",
        "        vmax = vmax_candidate\n",
        "        if vmax == 0: vmax = 1.0\n",
        "\n",
        "    masked_first = np.ma.masked_where(~mask, data_list[0])\n",
        "    pcm = ax.pcolormesh(X, Y, masked_first, shading='auto', cmap=cmap, vmin=0, vmax=vmax)\n",
        "\n",
        "    th = np.linspace(0, 2*np.pi, 200)\n",
        "    ax.plot(a*np.cos(th), b*np.sin(th), 'k-', lw=1.5, alpha=0.5)\n",
        "    ax.set_aspect('equal'); ax.axis('off')\n",
        "\n",
        "    def update(frame):\n",
        "        masked_data = np.ma.masked_where(~mask, data_list[frame])\n",
        "        pcm.set_array(masked_data.ravel())\n",
        "        title = f\"{title_prefix}\\nT={time_list[frame]*1000.0:.2f} ms\"\n",
        "        if leak_list is not None and frame < len(leak_list):\n",
        "            title += f\"\\nLeaked cum = {leak_list[frame]:.2e} mass\"\n",
        "        ax.set_title(title)\n",
        "        return pcm,\n",
        "\n",
        "    anim = animation.FuncAnimation(fig, update, frames=len(data_list), interval=80, blit=False)\n",
        "    anim.save(filename, writer=PillowWriter(fps=15))\n",
        "    plt.close(fig)\n",
        "\n",
        "scenarios_data = [\n",
        "    ('Case1', Hist_C1),\n",
        "    ('Case2', Hist_C2),\n",
        "    ('Case3', Hist_C3)\n",
        "]\n",
        "\n",
        "species_map = [('S', 'Blues'), ('I1', 'Purples'), ('I2', 'Oranges'), ('P', 'Reds')]\n",
        "\n",
        "print(\"\\n--- Generating GIFs ---\")\n",
        "for s_name, h_data in scenarios_data:\n",
        "    for spec, cmap in species_map:\n",
        "        fname = f\"{s_name}_{spec}.gif\"\n",
        "        if spec == 'P':\n",
        "            leak_list = h_data['P_leaked_cum']\n",
        "            save_gif(h_data[spec], h_data['time'], fname, f\"{s_name}: {spec}\", cmap, leak_list=leak_list)\n",
        "        else:\n",
        "            save_gif(h_data[spec], h_data['time'], fname, f\"{s_name}: {spec}\", cmap)\n",
        "\n",
        "print(\"All done.\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}